{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelWithLMHead\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simple Sentiment Analysis\n",
    "def nlp_sentiment_pd (sentences):\n",
    "    nlp = pipeline(\"sentiment-analysis\")\n",
    "    nlp_results = nlp(sentences)\n",
    "    nlp_results_pd = pd.DataFrame(nlp_results)\n",
    "    nlp_results_pd.insert(0, 'sentences', sentences)\n",
    "    nlp_results_pd = nlp_results_pd.sort_values('score', ascending=False)\n",
    "    return nlp_results_pd\n",
    "\n",
    "\n",
    "# Simple Paraphrase Analysis\n",
    "def nlp_paraphrase_pd(sequence_list, threshold=0.9):\n",
    "    if len(sequence_list)>1 and type(sequence_list) is list:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased-finetuned-mrpc\")\n",
    "\n",
    "        pairs_list = pair_list(sequence_list)\n",
    "        result_list = []\n",
    "\n",
    "        for sequence_pair in pairs_list:\n",
    "            token = tokenizer(sequence_pair[0], sequence_pair[1], return_tensors=\"pt\")\n",
    "            classification_logits = model(**token).logits\n",
    "            result = torch.softmax(classification_logits, dim=1).tolist()[0]\n",
    "            result_list.append(result)\n",
    "\n",
    "        pairs_pd = pd.DataFrame(pairs_list, columns=['sequence_1', 'sequence_2'])\n",
    "        results_pd = pd.DataFrame(result_list, columns=['not_paraphrase', 'is_paraphrase'])\n",
    "        results_pd.loc[results_pd['is_paraphrase']>=threshold, 'label'] = 'PARAPHRASE'\n",
    "        results_pd.loc[results_pd['not_paraphrase']>=threshold, 'label'] = 'NOT PARAPHRASE'\n",
    "        results_pd.loc[((results_pd['not_paraphrase']<threshold) & (results_pd['is_paraphrase']<threshold)), 'label'] = 'NOT SURE'\n",
    "        paraphrases_pd = pd.concat([pairs_pd, results_pd],ignore_index=False, axis=1)\n",
    "        paraphrases_pd = movecol(paraphrases_pd, cols_to_move=['label'], ref_col='sequence_2', place='After')\n",
    "        return paraphrases_pd\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Summarize text\n",
    "def nlp_summarizer_pd(list_text, max_length=200, min_length=100, do_sample=False):\n",
    "    summarizer = pipeline(\"summarization\")\n",
    "    for text in list_text:\n",
    "        summary_list = summarizer(text, max_length=max_length, min_length=min_length, do_sample=do_sample)\n",
    "    return summary_list\n",
    "    \n",
    "# Make sentence pair combinations\n",
    "def pair_list(sentences):\n",
    "    pair_list = []\n",
    "    if len(sentences)>1 and type(sentences) is list:\n",
    "        for x in range(len(sentences)):\n",
    "            for y in range(len(sentences)):\n",
    "                if x+1<=y:\n",
    "                    pair_list.append([sentences[x],sentences[y]])\n",
    "    else:\n",
    "        return None\n",
    "    return pair_list\n",
    "\n",
    "# Move columns in pd\n",
    "def movecol(df, cols_to_move=[], ref_col='', place='After'):\n",
    "    \n",
    "    cols = df.columns.tolist()\n",
    "    if place == 'After':\n",
    "        seg1 = cols[:list(cols).index(ref_col) + 1]\n",
    "        seg2 = cols_to_move\n",
    "    if place == 'Before':\n",
    "        seg1 = cols[:list(cols).index(ref_col)]\n",
    "        seg2 = cols_to_move + [ref_col]\n",
    "    \n",
    "    seg1 = [i for i in seg1 if i not in seg2]\n",
    "    seg3 = [i for i in cols if i not in seg1 + seg2]\n",
    "    \n",
    "    return(df[seg1 + seg2 + seg3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             sentences     label     score\n",
      "1           I love you  POSITIVE  0.999866\n",
      "2  Chenlei is very bad  NEGATIVE  0.999804\n",
      "0           I hate you  NEGATIVE  0.999113\n"
     ]
    }
   ],
   "source": [
    "sentences = [\"I hate you\", \\\n",
    "             \"I love you\", \\\n",
    "             \"Chenlei is very bad\"]\n",
    "\n",
    "print(nlp_sentiment_pd(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_list = [\"Helmut is Anna's brother\", \\\n",
    "                \"Anna is Helmut's sister\", \\\n",
    "                \"Helmut is also Anna's uncle\"]\n",
    "print(nlp_paraphrase_pd(sequence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \" The approval of a new drug to treat Alzheimer's is premature, risky and wrong . The FDA admits that it is not proven that the new drug, a monoclonal antibody to be sold under the name Aduhelm, actually works .\"}]\n"
     ]
    }
   ],
   "source": [
    "list_text = [open(\"./text.txt\", \"r\").read()]\n",
    "\n",
    "print (nlp_summarizer_pd(list_text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
